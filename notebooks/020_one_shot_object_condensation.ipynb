{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# One shot object condensation\n",
    "\n",
    "This notebook shows how you can implement a model that directly goes from point cloud data to object condensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pytorch_lightning.core.mixins.hparams_mixin import HyperparametersMixin\n",
    "from torch import nn\n",
    "from torch_geometric.nn.conv import GravNetConv\n",
    "from torch_geometric.data import Data\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from gnn_tracking.metrics.losses.oc import CondensationLossTiger\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "from gnn_tracking.training.callbacks import PrintValidationMetrics\n",
    "from gnn_tracking.training.tc import TCModule\n",
    "from gnn_tracking.utils.loading import TrackingDataModule\n",
    "from gnn_tracking.utils.versioning import assert_version_geq\n",
    "\n",
    "assert_version_geq(\"23.12.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. Configure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (\n",
    "    Path.cwd().resolve().parent.parent / \"test-data\" / \"data\" / \"point_clouds\" / \"v8\"\n",
    ")\n",
    "assert data_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TrackingDataModule(\n",
    "    train=dict(\n",
    "        dirs=[data_dir],\n",
    "        stop=1,\n",
    "    ),\n",
    "    val=dict(\n",
    "        dirs=[data_dir],\n",
    "        start=1,\n",
    "        stop=2,\n",
    "    ),\n",
    "    identifier=\"point_clouds_v8\"\n",
    "    # could also configure a 'test' set here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Write a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DemoGravNet(nn.Module, HyperparametersMixin):\n",
    "    def __init__(self, in_dim: int = 14, depth: int = 1, k: int = 2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = [\n",
    "            GravNetConv(\n",
    "                in_channels=in_dim,\n",
    "                out_channels=in_dim,\n",
    "                space_dimensions=3,\n",
    "                propagate_dimensions=3,\n",
    "                k=k,\n",
    "            )\n",
    "            for _ in range(depth)\n",
    "        ]\n",
    "        self._embedding = nn.Sequential(*layers)\n",
    "        self._beta = nn.Sequential(\n",
    "            nn.Linear(in_dim, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, data: Data):\n",
    "        latent = self._embedding(data.x)\n",
    "        beta = self._beta(latent).squeeze()\n",
    "        eps = 1e-6\n",
    "        beta = beta.clamp(eps, 1 - eps)\n",
    "        return {\n",
    "            \"B\": beta,\n",
    "            \"H\": latent,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = DemoGravNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Configure loss functions and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The loss functions can be memory hungry. Here we override `data_preproc` to place a tighter pt cut on\n",
    "# the data to easy computation (since this is just a demo).\n",
    "class PtCut(HyperparametersMixin):\n",
    "    def __call__(self, data: Data):\n",
    "        mask = data.pt > 4\n",
    "        data = data.subgraph(mask)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gnn_tracking.postprocessing.dbscanscanner import DBSCANHyperParamScanner\n",
    "\n",
    "# TC for track condensation\n",
    "lmodel = TCModule(\n",
    "    model=model,\n",
    "    loss_fct=CondensationLossTiger(\n",
    "        lw_repulsive=2.0,\n",
    "    ),\n",
    "    optimizer=partial(torch.optim.Adam, lr=1e-4),\n",
    "    cluster_scanner=DBSCANHyperParamScanner(n_trials=5, n_jobs=1),\n",
    "    preproc=PtCut(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3 ...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[15:52:19] INFO: DataLoader will load 1 graphs (out of 2 available).\u001b[0m\n",
      "\u001b[36m[15:52:19] DEBUG: First graph is /home/kl5675/Documents/23/git_sync/test-data/data/point_clouds/v8/data21000_s0.pt, last graph is /home/kl5675/Documents/23/git_sync/test-data/data/point_clouds/v8/data21000_s0.pt\u001b[0m\n",
      "\u001b[32m[15:52:19] INFO: DataLoader will load 1 graphs (out of 2 available).\u001b[0m\n",
      "\u001b[36m[15:52:19] DEBUG: First graph is /home/kl5675/Documents/23/git_sync/test-data/data/point_clouds/v8/data21001_s0.pt, last graph is /home/kl5675/Documents/23/git_sync/test-data/data/point_clouds/v8/data21001_s0.pt\u001b[0m\n",
      "\n",
      "  | Name     | Type                  | Params\n",
      "---------------------------------------------------\n",
      "0 | model    | DemoGravNet           | 399   \n",
      "1 | loss_fct | CondensationLossTiger | 0     \n",
      "---------------------------------------------------\n",
      "399       Trainable params\n",
      "0         Non-trainable params\n",
      "399       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |                                                                                                                                                                                                             | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/scratch/gpfs/kl5675/micromamba/envs/gnn'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                     \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: You called `self.log('n_rep', ...)` in your `validation_step` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'n_rep': ...})` instead.\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                                                                                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: You called `self.log('n_rep_train', ...)` in your `training_step` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'n_rep_train': ...})` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█| 1/1 [00:10<00:00,  0.09it/s, v_num=3, attractive_train=9.35e+7, repulsive_train=0.000, coward_train=0.0526, noise_train=nan.0, attractive_weighted_train=9.35e+7, repulsive_weighted_train=0.000, coward_weighted_train=0.000, noise"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                    Validation epoch=0                     \u001b[0m                                                                                                                                                                                  \n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m         Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m55245000.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_train               │ 93512936.00000 │   nan │\n",
      "│ attractive_weighted            │ 55245000.00000 │   nan │\n",
      "│ attractive_weighted_train      │ 93512936.00000 │   nan │\n",
      "│ best_dbscan_eps                │        0.15979 │   nan │\n",
      "│ best_dbscan_min_samples        │        4.00000 │   nan │\n",
      "│ coward                         │        0.03412 │   nan │\n",
      "│ coward_train                   │        0.05263 │   nan │\n",
      "│ coward_weighted                │        0.00000 │   nan │\n",
      "│ coward_weighted_train          │        0.00000 │   nan │\n",
      "│ n_rep                          │        1.00000 │   nan │\n",
      "│ n_rep_train                    │        0.00000 │   nan │\n",
      "│ noise                          │            nan │   nan │\n",
      "│ noise_train                    │            nan │   nan │\n",
      "│ noise_weighted                 │            nan │   nan │\n",
      "│ noise_weighted_train           │            nan │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m       0.00112\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_train                │        0.00000 │   nan │\n",
      "│ repulsive_weighted             │        0.00223 │   nan │\n",
      "│ repulsive_weighted_train       │        0.00000 │   nan │\n",
      "│ total                          │            nan │   nan │\n",
      "│ total_train                    │            nan │   nan │\n",
      "│ trk.double_majority            │        0.00000 │   nan │\n",
      "│ trk.double_majority_pt0.5      │        0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m       0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │        0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │            nan │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │            nan │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │            nan │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │            nan │   nan │\n",
      "│ trk.fake_lhc                   │            nan │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │            nan │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │            nan │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │            nan │   nan │\n",
      "│ trk.fake_perfect               │            nan │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │            nan │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │            nan │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │            nan │   nan │\n",
      "│ trk.i_batch                    │        0.00000 │   nan │\n",
      "│ trk.lhc                        │            nan │   nan │\n",
      "│ trk.lhc_pt0.5                  │            nan │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m           nan\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │            nan │   nan │\n",
      "│ trk.n_cleaned_clusters         │        0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │        0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │        0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │        0.00000 │   nan │\n",
      "│ trk.n_particles                │       17.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │       17.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │       17.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │       17.00000 │   nan │\n",
      "│ trk.perfect                    │        0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │        0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m       0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │        0.00000 │   nan │\n",
      "└────────────────────────────────┴────────────────┴───────┘\n",
      "\n",
      "Epoch 0: 100%|█| 1/1 [00:11<00:00,  0.09it/s, v_num=3, attractive_train=9.35e+7, repulsive_train=0.000, coward_train=0.0526, noise_train=nan.0, attractive_weighted_train=9.35e+7, repulsive_weighted_train=0.000, coward_weighted_train=0.000, noise"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█| 1/1 [00:11<00:00,  0.09it/s, v_num=3, attractive_train=9.35e+7, repulsive_train=0.000, coward_train=0.0526, noise_train=nan.0, attractive_weighted_train=9.35e+7, repulsive_weighted_train=0.000, coward_weighted_train=0.000, noise\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=1,\n",
    "    accelerator=\"cpu\",\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[PrintValidationMetrics()],\n",
    ")\n",
    "trainer.fit(model=lmodel, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
